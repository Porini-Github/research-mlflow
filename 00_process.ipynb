{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Preamboli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_version(dataset_name: str, df: pd.DataFrame):\n",
    "    # Percorso della cartella dataset\n",
    "    base_dir = \"datasets\"\n",
    "    dataset_dir = os.path.join(base_dir, dataset_name)\n",
    "    \n",
    "    # Crea la cartella se non esiste\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    \n",
    "    # Trova i file già presenti che matchano lo schema vXX.csv\n",
    "    existing_files = [f for f in os.listdir(dataset_dir) if re.match(r\"v\\d{2}\\.csv\", f)]\n",
    "    \n",
    "    if not existing_files:\n",
    "        # Se non ci sono file, la prima versione è v01\n",
    "        version_number = 1\n",
    "    else:\n",
    "        # Estrai i numeri delle versioni dai file\n",
    "        versions = [int(re.findall(r\"\\d{2}\", f)[0]) for f in existing_files]\n",
    "        version_number = max(versions) + 1\n",
    "    \n",
    "    # Nome del file da salvare\n",
    "    filename = f\"v{version_number:02d}.csv\"\n",
    "    filepath = os.path.join(dataset_dir, filename)\n",
    "    \n",
    "    # Salva il dataframe\n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    return filepath, version_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 2. Import e versioning del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"iris_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carichiamo il dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo il dataset versionato localmente (puoi anche usare DVC o Git LFS)\n",
    "dataset_path, dataset_version = save_dataset_version(dataset_name, df)\n",
    "\n",
    "print(f\"Dataset salvato in: {dataset_path}\")\n",
    "print(f\"Versione del dataset: {dataset_version}\")\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X = df[iris.feature_names]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 3. Setup MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impostiamo il nome dell'esperimento\n",
    "mlflow.set_experiment(\"Iris_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione helper per loggare esperimenti\n",
    "def train_and_log_model(model_name=\"IrisClassifier\",\n",
    "                        model_dict = {\n",
    "                            \"model\": \"RandomForest\",\n",
    "                            \"n_estimators\": 100,\n",
    "                            \"max_depth\": None\n",
    "                        },\n",
    "                        dataset_version=None):\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "\n",
    "        if model_dict[\"model\"] == \"RandomForest\":\n",
    "            # 1. Crea il modello\n",
    "            model = RandomForestClassifier(n_estimators=model_dict[\"n_estimators\"], max_depth=model_dict[\"max_depth\"], random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            mlflow.log_param(\"n_estimators\", model_dict[\"n_estimators\"])\n",
    "            mlflow.log_param(\"max_depth\", model_dict[\"max_depth\"])\n",
    "\n",
    "            # # Log feature importance (se utile per analisi)\n",
    "            # feature_importances = dict(zip(X_train.columns, model.feature_importances_))\n",
    "            # mlflow.log_dict(feature_importances, \"feature_importances.json\")\n",
    "\n",
    "        elif model_dict[\"model\"] == \"LogisticRegression\":\n",
    "            model = LogisticRegression(max_iter=model_dict[\"max_iter\"], random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            mlflow.log_param(\"max_iter\", model_dict[\"max_iter\"])\n",
    "\n",
    "\n",
    "        # 2. Previsioni e metriche\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        prec = precision_score(y_test, preds, average=\"weighted\")\n",
    "        rec = recall_score(y_test, preds, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "\n",
    "        # 3. Log parametri principali del modello\n",
    "        mlflow.log_param(\"model_class\", model_dict[\"model\"])\n",
    "        if dataset_version is not None:\n",
    "            mlflow.log_param(\"dataset_version\", dataset_version)\n",
    "\n",
    "        # 4. Log metriche\n",
    "        mlflow.log_metric(\"accuracy\", round( float(acc), 2))\n",
    "        mlflow.log_metric(\"precision_weighted\", round( float(prec), 2))\n",
    "        mlflow.log_metric(\"recall_weighted\", round( float(rec), 2))\n",
    "        mlflow.log_metric(\"f1_weighted\", round( float(f1), 2))\n",
    "\n",
    "        # 5. Log del modello e dell’ambiente\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=model_name)\n",
    "        # mlflow.log_dict({\n",
    "        #     \"python_version\": sys.version,\n",
    "        #     \"platform\": platform.platform(),\n",
    "        #     \"mlflow_version\": mlflow.__version__,\n",
    "        #     \"sklearn_version\": model.__module__.split('.')[0]\n",
    "        # }, \"environment_info.json\")\n",
    "\n",
    "        # N.B. Non per forza tutti i modelli vanno registrati. \n",
    "        # Volendo, si può decidere di non registrare i modelli dentro questo codice, ma decidere a posteriori quali registrare e quali no\n",
    "\n",
    "        # 6. Log di due righe di esempio dal dataset\n",
    "        sample_input = X_train.head(2).copy()\n",
    "        sample_input[\"target\"] = y_train.iloc[:2].values\n",
    "        mlflow.log_table(sample_input, \"sample_input.parquet\")\n",
    "\n",
    "        # 7. Stampa riassunto\n",
    "        print(f\"Run {run.info.run_id} - Acc: {acc:.4f}\")\n",
    "        \n",
    "        return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100 # 50 # 100\n",
    "max_depth = 5 # 3 # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_randomforest = {\"model\": \"RandomForest\",\n",
    "    \"n_estimators\": 50, # 100 , 50\n",
    "    \"max_depth\": 5    # 3 , 5\n",
    "    }\n",
    "\n",
    "D_logistic = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"max_iter\": 100 # 1000, 500\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo alcuni esperimenti con parametri diversi\n",
    "run_id = train_and_log_model(   model_name = \"Iris_Classifier\",\n",
    "                                model_dict = D_randomforest,\n",
    "                                dataset_version = dataset_version,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# 4. Gestione dei modelli e MLflow Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome del modello registrato\n",
    "MODEL_NAME = \"Iris_Classifier\"\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 1. Prendi tutte le versioni registrate del modello\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "# 2. Trova l'accuracy migliore tra i run\n",
    "best_run_id = None\n",
    "best_accuracy = -1.0\n",
    "best_model_version = None\n",
    "\n",
    "for v in versions:\n",
    "    run_id = v.run_id\n",
    "    metrics = client.get_run(run_id).data.metrics\n",
    "    acc = metrics.get(\"accuracy\", None)\n",
    "    if acc is not None and acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_run_id = run_id\n",
    "        best_model_version = v.version\n",
    "\n",
    "print(f\"Miglior modello trovato: run_id={best_run_id}, versione={best_model_version}, accuracy={best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import Metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_to_dict(metric):\n",
    "    return {\n",
    "        \"key\": metric.key,\n",
    "        \"value\": metric.value,\n",
    "        \"timestamp\": metric.timestamp,\n",
    "        \"step\": metric.step\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "import time\n",
    "\n",
    "# Inizializza il client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Nome del modello registrato e versione che vuoi modificare\n",
    "model_name = \"Iris_Classifier\"\n",
    "model_version = 1  # la versione che vuoi promuovere o spostare\n",
    "\n",
    "# Numero massimo di tentativi\n",
    "max_retries = 3\n",
    "retry_delay = 2  # secondi\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        # Sposta il modello in staging\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=model_version,\n",
    "            stage=\"Staging\",   # opzioni: \"None\", \"Staging\", \"Production\", \"Archived\"\n",
    "            archive_existing_versions=False  # se True, sposta automaticamente le versioni esistenti dalla stessa fase in Archived\n",
    "        )\n",
    "        print(f\"Modello {model_name} versione {model_version} spostato in Staging con successo\")\n",
    "        break  # Esci dal ciclo se l'operazione ha successo\n",
    "        \n",
    "    except MlflowException as e:\n",
    "        print(f\"Tentativo {attempt + 1} fallito: {e}\")\n",
    "        \n",
    "        # Se non è l'ultimo tentativo, aspetta prima di riprovare\n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Riprovo tra {retry_delay} secondi...\")\n",
    "            time.sleep(retry_delay)\n",
    "        else:\n",
    "            print(\"Numero massimo di tentativi raggiunto. Operazione fallita.\")\n",
    "            # Qui puoi aggiungere ulteriori azioni di fallback se necessario\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Errore imprevisto: {e}\")\n",
    "        break  # Interrompi per errori non previsti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Aggiorna lo stato del modello migliore (es. in Production)\n",
    "# if best_model_version is not None:\n",
    "#     client.transition_model_version_stage(\n",
    "#         name=MODEL_NAME,\n",
    "#         version=best_model_version,\n",
    "#         stage=\"Staging\",   # oppure \"Staging\"\n",
    "#         archive_existing_versions=True  # sposta gli altri modelli fuori da Production\n",
    "#     )\n",
    "#     print(f\"Il modello versione {best_model_version} è stato promosso a Production.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
