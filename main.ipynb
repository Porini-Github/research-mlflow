{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Preamboli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from utils import load_dataset, train_and_log_model\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient, dsl, command, Input, Output\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb858df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.secret import (\n",
    "                             SUBSCRIPTION_ID\n",
    "                            ,RESOURCE_GROUP_NAME\n",
    "                            ,WORKSPACE_NAME\n",
    "                            ,ENVIRONMENT_NAME\n",
    "                            ,ENVIRONMENT_VERSION\n",
    "                            ,COMPUTE_NAME\n",
    "                            ,DATASTORE_NAME\n",
    "                            ,BLOB_ACCOUNT_URL\n",
    "                            ,BLOB_CONTAINER_NAME\n",
    "                            ,MANAGED_IDENTITY_CLIENT_ID\n",
    "                        )\n",
    "\n",
    "DATASTORE_URI = f\"azureml://subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP_NAME}/workspaces/{WORKSPACE_NAME}/datastores/{DATASTORE_NAME}/paths/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f02102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config import DEFAULT_INPUT_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71c00d",
   "metadata": {},
   "source": [
    "# 2. Autenticazione e preparazione environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1c9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential(\n",
    "    managed_identity_client_id=MANAGED_IDENTITY_CLIENT_ID\n",
    ")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP_NAME,\n",
    "    workspace_name=WORKSPACE_NAME,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a103731",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ml_client.environments.get( name = ENVIRONMENT_NAME,\n",
    "                                  version = ENVIRONMENT_VERSION\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e4b96",
   "metadata": {},
   "source": [
    "# 3. Creazione di una Componente per ogni step del ciclo di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e82fe2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'env-training' will not be used for anonymous registration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading research-mlflow (0.15 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150971/150971 [00:00<00:00, 391522.45it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_command = command(\n",
    "    name='training_create_data',\n",
    "    command=\"python -m components.01_create_data --input_file_path ${{inputs.input_file_path}} --experiment_name ${{inputs.experiment_name}} --data_asset_name ${{inputs.data_asset_name}} --create_output_path ${{outputs.create_output_path}}\",\n",
    "    environment=env,\n",
    "    code='./',\n",
    "    inputs={'input_file_path': Input(type='string'),\n",
    "            'experiment_name': Input(type='string'), \n",
    "            'data_asset_name': Input(type='string')},\n",
    "    outputs={'create_output_path': Output(type='uri_folder', mode='ro_mount')}\n",
    "    )\n",
    "create_component = ml_client.create_or_update(create_command.component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f1209",
   "metadata": {},
   "source": [
    "# 4. Definizione della pipeline (job) ed esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fac8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(default_compute=\"cc-azml-01-dev\")\n",
    "def training_pipeline_job(experiment_name, timestamp):\n",
    "    create_job = create_component(input_file_path = DEFAULT_INPUT_FILE_PATH,\n",
    "                                  experiment_name = experiment_name,\n",
    "                                  data_asset_name = 'raw_forecasting_dataset')\n",
    "    # clean_job = clean_component(create_output_path = create_job.outputs.create_output_path,\n",
    "    #                             clean_file_path = DEFAULT_CLEAN_FILE_PATH,\n",
    "    #                             clean_data_asset_name = 'forecasting_dataset',\n",
    "    #                             target_column = 'y',\n",
    "    #                             date_column = 'date')\n",
    "    # train_job = train_component(clean_output_path = clean_job.outputs.clean_output_path,\n",
    "    #                             model_name = 'ForecastModel')\n",
    "    # deploy_job = deploy_component(train_output_path = train_job.outputs.train_output_path,\n",
    "    #                               endpoint_name = DEFAULT_ENDPOINT_NAME,\n",
    "    #                               deployment_name = DEFAULT_DEPLOYMENT_NAME,\n",
    "    #                               environment_name = env_name,\n",
    "    #                               environment_version = str(env_version),\n",
    "    #                               compute = 'cc1-dev03')\n",
    "    # inference_job = inference_component(deploy_output_path = deploy_job.outputs.deploy_output_path,\n",
    "    #                                     input_data_asset_name = 'raw_forecasting_dataset',\n",
    "    #                                     output_data_path = f'batch_output_{timestamp}/{DEFAULT_OUTPUT_DATA_PATH}',\n",
    "    #                                     output_data_asset_name = 'forecasting_prediction')\n",
    "\n",
    "experiment_name = 'training_experiment_0'\n",
    "timestamp = datetime.now(tz=ZoneInfo(\"Europe/Rome\")).strftime(\"%Y%m%d_%H%M%S\")\n",
    "pipeline = training_pipeline_job(experiment_name, timestamp)\n",
    "pipeline_job = ml_client.jobs.create_or_update(pipeline,\n",
    "                                               experiment_name=experiment_name\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Import e versioning del dataset\n",
    "Viene importato il dataset di esempio (iris oppure breast cancer, in base al parametro settato).\n",
    "\n",
    "Questo dataset viene salvato in locale e versionato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parametro da settare per scegliere il dataset\n",
    "example_name = \"breast_cancer\" # \"breast_cancer\" / \"iris\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "- *breast cancer dataset:* problema di classificazione binaria (benigno/maligno), 30 features, 569 campioni\n",
    "- *iris dataset:* problema di classificazione multi-classe (setosa/versicolor/virginica), 4 features, 150 campioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvato in: datasets/breast_cancer_dataset/v01.csv\n",
      "Versione del dataset: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = f\"{example_name}_dataset\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, dataset_version, dataset_path, df = load_dataset(dataset_name)\n",
    "\n",
    "print(f\"Dataset salvato in: {dataset_path}\")\n",
    "print(f\"Versione del dataset: {dataset_version}\")\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# 3. Setup MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per impostare l'URI di tracciamento\n",
    "# mlflow.set_tracking_uri(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Lasciando il paramtro di default (in mlflow.set_tracking_uri), i dati vengono salvati in locale nella cartella \"mlruns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedModelRegistryStoreURIException",
     "evalue": " Model registry functionality is unavailable; got unsupported URI 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/30101379-480a-4fdc-88d3-c30601a89b44/resourceGroups/rg-azml-demo-dev/providers/Microsoft.MachineLearningServices/workspaces/mlw-azml-demo-dev' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/registry.py:81\u001b[0m, in \u001b[0;36mStoreRegistry.get_store_builder\u001b[0;34m(self, store_uri)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     store_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'azureml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnsupportedModelRegistryStoreURIException\u001b[0m Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Impostiamo il nome dell'esperimento\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexample_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_Classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/fluent.py:179\u001b[0m, in \u001b[0;36mset_experiment\u001b[0;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    172\u001b[0m     experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    173\u001b[0m ):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    175\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify exactly one of: `experiment_id` or `experiment_name`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    177\u001b[0m     )\n\u001b[0;32m--> 179\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_resolve_tracking_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:86\u001b[0m, in \u001b[0;36mTrackingServiceClient.__init__\u001b[0;34m(self, tracking_uri)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri \u001b[38;5;241m=\u001b[39m tracking_uri\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:90\u001b[0m, in \u001b[0;36mTrackingServiceClient.store\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py:215\u001b[0m, in \u001b[0;36m_get_store\u001b[0;34m(store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_store\u001b[39m(store_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py:45\u001b[0m, in \u001b[0;36mTrackingStoreRegistry.get_store\u001b[0;34m(self, store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tracking_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     44\u001b[0m resolved_store_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_resolve_tracking_uri(store_uri)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py:55\u001b[0m, in \u001b[0;36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[0;34m(self, resolved_store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mRetrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mCaching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mdepending on external configuration, such as environment variables\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[0;32m---> 55\u001b[0m     builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder(store_uri\u001b[38;5;241m=\u001b[39mresolved_store_uri, artifact_uri\u001b[38;5;241m=\u001b[39martifact_uri)\n",
      "File \u001b[0;32m~/cloudfiles/code/Users/stefano.biavaschi/research-mlflow/.venv/lib/python3.10/site-packages/mlflow/tracking/registry.py:83\u001b[0m, in \u001b[0;36mStoreRegistry.get_store_builder\u001b[0;34m(self, store_uri)\u001b[0m\n\u001b[1;32m     81\u001b[0m     store_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry[scheme]\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedModelRegistryStoreURIException(\n\u001b[1;32m     84\u001b[0m         unsupported_uri\u001b[38;5;241m=\u001b[39mstore_uri, supported_uri_schemes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store_builder\n",
      "\u001b[0;31mUnsupportedModelRegistryStoreURIException\u001b[0m:  Model registry functionality is unavailable; got unsupported URI 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/30101379-480a-4fdc-88d3-c30601a89b44/resourceGroups/rg-azml-demo-dev/providers/Microsoft.MachineLearningServices/workspaces/mlw-azml-demo-dev' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations."
     ]
    }
   ],
   "source": [
    "# Impostiamo il nome dell'esperimento\n",
    "mlflow.set_experiment(f\"{example_name}_Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "L'esperimento risulta come una sorta di \"cartella\" sulla UI mlflow per suddividere il tracking di varie runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Runs\n",
    "\n",
    "Vengono effettuate 4 runs diverse per sperimentare 4 diverse combinazioni di parametri nel training del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_randomforest_1 = {\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"n_estimators\": 10, \n",
    "    \"max_depth\": 3,\n",
    "    }\n",
    "\n",
    "D_randomforest_2= {\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"n_estimators\": 20, \n",
    "    \"max_depth\": 5,\n",
    "    }\n",
    "\n",
    "D_logistic_1 = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"max_iter\": 10\n",
    "    }\n",
    "\n",
    "D_logistic_2 = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"max_iter\": 15\n",
    "    }\n",
    "\n",
    "D_list = [D_randomforest_1, D_randomforest_2, D_logistic_1, D_logistic_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"{example_name}_Classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in D_list:\n",
    "    # Eseguiamo alcuni esperimenti con parametri diversi\n",
    "    run_id = train_and_log_model(   model_name = MODEL_NAME,\n",
    "                                    model_dict = D,\n",
    "                                    X_train = X_train,\n",
    "                                    X_test = X_test,\n",
    "                                    y_train = y_train,\n",
    "                                    y_test = y_test,\n",
    "                                    dataset_version = dataset_version,\n",
    "                                    dataset_name = dataset_name,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 4. Gestione dei modelli e MLflow Model Registry\n",
    "\n",
    "In questo esempio viene ricercato il modello migliore (con un accuracy più alta) tra tutti quelli registrati sotto \"MODEL_NAME\".\n",
    "\n",
    "Successivamente, al modello migliore viene effettuato un cambio di stato, settandolo come modello \"in produzione\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "# 1. Prendi tutte le versioni registrate del modello\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "# 2. Trova l'accuracy migliore tra i run\n",
    "best_run_id = None\n",
    "best_accuracy = -1.0\n",
    "best_model_version = None\n",
    "\n",
    "for v in versions:\n",
    "    run_id = v.run_id\n",
    "    metrics = client.get_run(run_id).data.params\n",
    "    acc = metrics.get(\"accuracy\", None)\n",
    "    if acc is not None and float(acc) > best_accuracy:\n",
    "        best_accuracy = float(acc)\n",
    "        best_run_id = run_id\n",
    "        best_model_version = v.version\n",
    "\n",
    "print(f\"Miglior modello trovato: run_id={best_run_id}, versione={best_model_version}, accuracy={best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aggiorna lo stato del modello migliore (es. in Production)\n",
    "if best_model_version is not None:\n",
    "    client.transition_model_version_stage(\n",
    "        name=MODEL_NAME,\n",
    "        version=best_model_version,\n",
    "        stage=\"Production\",   # oppure \"Staging\"\n",
    "        archive_existing_versions=True  # sposta gli altri modelli fuori da Production\n",
    "    )\n",
    "    print(f\"Il modello versione {best_model_version} è stato promosso a Production.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 5. Inference\n",
    "Esempio di inferenza:\n",
    "\n",
    "Utilizzando il modello che è stato messo in produzione, viene fatta inferenza utilizzando 3 nuovi record del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara nuovi dati di input (stesso schema usato in addestramento)\n",
    "if example_name == \"iris\":\n",
    "    # Qui uso l'Iris dataset come esempio\n",
    "    new_data = pd.DataFrame({\n",
    "        \"sepal length (cm)\": [5.1, 6.2, 5.9],\n",
    "        \"sepal width (cm)\":  [3.5, 2.9, 3.0],\n",
    "        \"petal length (cm)\": [1.4, 4.3, 5.1],\n",
    "        \"petal width (cm)\":  [0.2, 1.3, 1.8],\n",
    "    })\n",
    "\n",
    "\n",
    "elif example_name == \"breast_cancer\":\n",
    "    new_data = pd.DataFrame({\n",
    "        \"mean radius\": [14.0, 20.0, 13.5],\n",
    "        \"mean texture\": [20.0, 30.0, 15.0],\n",
    "        \"mean perimeter\": [90.0, 130.0, 85.0],\n",
    "        \"mean area\": [600.0, 1200.0, 500.0],\n",
    "        \"mean smoothness\": [0.1, 0.15, 0.09],\n",
    "        \"mean compactness\": [0.1, 0.2, 0.08],\n",
    "        \"mean concavity\": [0.05, 0.1, 0.04],\n",
    "        \"mean concave points\": [0.02, 0.05, 0.01],\n",
    "        \"mean symmetry\": [0.2, 0.3, 0.18],\n",
    "        \"mean fractal dimension\": [0.06, 0.07, 0.05],\n",
    "        \"radius error\": [0.3, 0.4, 0.2],\n",
    "        \"texture error\": [1.5, 2.0, 1.2],\n",
    "        \"perimeter error\": [2.5, 3.5, 2.0],\n",
    "        \"area error\": [20.0, 30.0, 15.0],\n",
    "        \"smoothness error\": [0.005, 0.007, 0.004],\n",
    "        \"compactness error\": [0.02, 0.03, 0.015],\n",
    "        \"concavity error\": [0.02, 0.025, 0.01],\n",
    "        \"concave points error\": [0.01, 0.015, 0.008],\n",
    "        \"symmetry error\": [0.02, 0.03, 0.015],\n",
    "        \"fractal dimension error\": [0.003, 0.004, 0.002],\n",
    "        \"worst radius\": [16.0, 25.0, 14.5],\n",
    "        \"worst texture\": [25.0, 40.0, 20.0],\n",
    "        \"worst perimeter\": [110.0, 160.0, 95.0],\n",
    "        \"worst area\": [800.0, 1500.0, 600.0],\n",
    "        \"worst smoothness\": [0.15, 0.2, 0.12],\n",
    "        \"worst compactness\": [0.25, 0.3, 0.2],\n",
    "        \"worst concavity\": [0.15, 0.2, 0.1],\n",
    "        \"worst concave points\": [0.07, 0.1, 0.05],\n",
    "        \"worst symmetry\": [0.3, 0.4, 0.25],\n",
    "        \"worst fractal dimension\": [0.08, 0.1, 0.07],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera il modello in produzione\n",
    "model_uri = f\"models:/{MODEL_NAME}/Production\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "\n",
    "# Esegui inferenza\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "print(\"Inferenza:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Per fare pratica:\n",
    "- Utilizzare un dataset differente, un dataset custom o un altro pubblico tipo \"wine quality\", basta che sia un problema di classificazione. Eventualmente, serve modificare il parametro \"example_name\", la funzione \"load_dataset\" e modificare i \"new_data\" per la parte di inferenza.\n",
    "- Sperimentare più combinazioni di parametri/modelli.\n",
    "- Aggiungere metriche di valutazione del modello (e loggarle su mlflow).\n",
    "- Parametrizzare la logica di split train/test (e loggarla come parametro su mlflow).\n",
    "- Cambiare di stato i modelli nel model registry sulla base di logiche a propria scelta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
